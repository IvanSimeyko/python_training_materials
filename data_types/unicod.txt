Кодировкой, называют способ представления в памяти компьютера (читай — в нулях-единицах\числах) цифр, буков и всех остальных знаков. Например, пробел представляется как 0b100000 (в двоичной), 32 (в десятичной) или 0x20 (в шестнадцатеричной системе счисления).

когда-то памяти было совсем немного и всем компьютерам было достаточно 7 бит для представления всех нужных символов (цифры, строчный\прописной латинский алфавит, куча знаков и так называемые управляемые символы — все возможные 127 номеров были кому-то отданы). Кодировка в это время была одна — ASCII.
Пробелу соответствовало число 32, букве "A" -- 65 и т.д. Это позволило использовать 7 бит для хранения символов. Большинство компьютеров в те дни использовало 8-битовые регистры, и таким образом вы не только могли хранить любой возможный символ ASCII, но ещё и имели целый бит экономии, который, если у вас была такая блажь, можно было использовать в собственных левых целях. Коды меньше 32 назывались непечатными. Они использовались для управляющих символов, например, символ 7 заставлял ваш компьютер пискнуть, а символ 12 являлся символом конца страницы, заставляя принтер выплюнуть текущий лист бумаги и загрузить новый.
И все было прекрасно, правда, только если вы говорили на английском.

 Шло время, все были счастливы, а кто не был счастлив (читай — кому не хватало знака "" или родной буквы «щ») — использовали оставшиеся 128 знаков на свое усмотрение, то есть создавали новые кодировки. Поскольку байты имеют восемь битов, то многие люди думали: "Чёрт возьми, мы же можем использовать коды 128-255 в наших собственных целях!".
Так появились и ISO-8859-1, и наши (то есть кириличные) cp1251 и KOI8. Вместе с ними появилась и проблема интерпретации байтов типа 0b1******* (то есть символов\чисел от 128 и до 255) — например, 0b11011111 в кодировке cp1251 это наша родная «Я», в тоже время в кодировке ISO-8859-1 это греческая немецкая Eszett (подсказывает Moonrise) "ß".

В этот момент собрались светлые умы и предложили новый стандарт — Unicode. Это именно стандарт, а не кодировка — сам по себе Юникод не определяет, как символы будут сохранятся на жестком диске или передаваться по сети. Он лишь определяет связь между символом и некоторым числом, а формат, согласно с которым эти числа будут превращаться в байты, определяется Юникод-кодировками (например, UTF-8 или UTF-16). На данный момент в Юникод-стандарте есть немного более 100 тысяч символов, тогда как UTF-16 позволяет поддерживать более одного миллиона (UTF-8 — и того больше).

Некоторые люди имеют неправильное представление, что Unicode -- это обычный 16-битовый код, где каждый символ занимает 16 битов и поэтому есть 65,536 возможных символов. На самом деле это не верно. Каждой букве в каждом алфавите консорциумом Unicode было назначено волшебное число, которое записывается так, как это: U+0645. Это волшебное число называют кодовой точкой. U+ означает "Unicode", а числа являются шестнадцатеричными. Число U+FEC9 является арабской буквой Аин (Ain). Английская буква A соответствует U+0041. Вы можете найти все буквы, воспользовавшись утилитой Таблица символов (charmap) в Windows 2000/XP или посетив вебсайт Unicode.

есть поддержка Юникода и в Пайтоне, но только в Python 3 все строки стали юникодом. Что такое строка в Python 2.x? Это просто байты. Просто бинарные данные, которые могут быть чем-угодно.

«type unicode» — это прежде всего абстракция, которая реализует идею Юникода (набор символов и связанных с ними чисел). Объект типа «unicode» — это уже не последовательность байт, но последовательность собственно символов без какого либо представления о том, как эти символы эффективно сохранить в памяти компьютера. Если хотите — это более высокой уровень абстракции, чем байтовый строки (именно так в Python 3 называют обычные строки, которые используются в Python 2.6).

Юникод-строку в Python 2.6 можно создать тремя (как минимум, естественно) способами:
u"" литерал:
>>> u'abc'
u'abc'

Метод «decode» для байтовой строки:
>>> 'abc'.decode('ascii')
u'abc'

>>> unicode('abc', 'ascii')
u'abc'


Как из юникод-строки получить обычную? Закодировать её:
>>> u'abc'.encode('ascii')
'abc'


